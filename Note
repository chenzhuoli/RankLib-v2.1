一、LambdaMart数据预处理
文件DataPoint.java：ciir.umass.edu.learning.DataPoint
/*****************************************************/
1、数据格式：lable qid:xx fid1:xx fid2:xx … fid:xx#description
例如：0 qid:1 1:3 2:0 3:2 4:2 ... 135:0 136:0#description
label是人工划分的等级，比如：差、一般、好、优秀、完美的等级是0、1、2、3、4、5；它是自定义的等级，比如范围可以扩大到0~100或者0~10000，label=0表示此文档与query不相关。
qid是搜索词的query_id，比如搜索词“范冰冰”的qid:60
fid是feature特征ID，比如销量的fid:1
description是注释，在算法里不起作用，它用#与其它部分隔离开
/*****************************************************/
2、数据解析
第1列的数字存进float型变量label
第2列的qid:xx存进string型变量id
第3列至#前的fid1:xx fid2:xx … fidn:xx存进float型数组fVals，数组的下标是fidN中的N，数组的值是fidN:xx中的xx
#符号后的字符串存放进description变量
/*****************************************************/
3、数据预处理
public void evaluate(String trainFile, String validationFile, String testFile, String featureDefFile)
(1)	读入文件：
读入四个文件：trainFile，testFile，validationFile和featureDefFile。
trainFile：训练数据文件
testFile：测试数据文件
validationFile：验证数据文件
featureDefFile：自定义的feature文件，它指定了算法用到的特征编号，如果未指定则默认使用全部特征值来建立搜索排序模型。
(2) 归一化方法：
SumNormalizor的归一化方法：先把一个query召回的文档RankList的全部样本点datapoint遍历一遍，把第j个feature的样本点的值累加存进norm[j]，从而得到第j个feature的样本累加值norm[j]，然后把一个样本点的feature值/norm[j]=归一化后此样本点的feature值。用到的代码有：SumNormalizor的归一化函数normalize(RankList rl, int[] fids)。
ZScoreNormalizor的归一化方法：先把一个query召回的文档RankList的全部样本点DataPoint遍历一遍，把第j个feature的全部样本值累加求和，再除以样本点个数得到平均值mean[j]，用这个DataPoint样本点在第j个feature的样本值减掉平均值得到中间值x。把第j个feature名下的全部样本点的x^2的值累加得到std[j]，样本点归一化的值=(fids[j]) - mean[j])/std[j]。用到的代码有：ZScoreNormalizor的归一化函数normalize(RankList rl, int[] fids)。
二、LambdaMart训练模型的过程
LambdaMart训练模型的管控函数是learn()，训练出模型model的整个过程如下：
/*****************************************************/
1.	整个过程是一个梯度提升的训练过程，它是训练nTrees=1000棵回归树，nTrees数目可自定义。
for(int m=0; m<nTrees; m++) //nTrees=1000

2.每训练出一棵树就添加进模型model里，那训练一棵树的过程如下：
(1)计算lambda值。lambda是每个文档的调整排序的趋势，+往上，-往下，值越大趋势越强。LambdaMart用的是pairwise方法，遍历所有的训练数据，把label不同的任意两个文档组合成文档对pair(Doc[i]，Doc[j])，计算每个pair互换位置导致的指标变化  以及Lambda，即  ，然后计算每个文档的Lambda：  ，再计算每个  的导数wi，用于后面的Newton step求解叶子节点的数值。
	computePseudoResponses();
理论公式对应的代码段是：
	double deltaNDCG = Math.abs(changes[j][k]); 
// deltaNDCG是j和k文档对pair互换位置导致的指标变化
double rho = 1.0 / (1 + Math.exp(modelScores[current+j] -modelScores[current+k]));
// modelScores[current+j]是根据特征向量得到的每个文档的分数值si = f(xi)
// rho是Ui比Uj排序更高的模型预测概率。
double lambda = rho * deltaNDCG;
lambdas[j] += lambda;
lambdas[k] -= lambda;
double delta = rho * (1.0 - rho) * deltaNDCG;
weights[j] += delta;
weights[k] += delta;

// 新增内容：对应上述代码里的deltaNDCG变量的值changes[j][k]
// 文件ReciprocalRankScorer.java：src.ciir.umass.edu.metric.ReciprocalRankScorer
// 函数：double[][] swapChange(RankList rl)
// 功能：pairwise构建文档对pair(doc[i], doc[j])，在交换两个文档doc[i]和doc[j]的位置时，指标的变化值changes的计算过程

/*****************************************************/
(2)用label (lambda)值来更新直方图hist，用lambda更新sum和sqSum变量。
首先它是把每一个feature特征的样本值先去重，再划分梯度。nThreshold=256，如果一个特征的样本值个数在去重后小于256，就把每一个样本值作为梯度值；若去重后的样本值个数在去重后大于256个，梯度值=(Max-Min)/256。
其次求出sum和sqSum，sum[i]是第i个feature在每个梯度的label总和；sqSum[i]是第i个feature在每个梯度label的平方和，它们是用来求MSE(均方误差?)，从而衡量最优回归决策树的变量。
代码段：hist.update(pseudoResponses);
//for(int f=0;f<features.length;f++)
// {
//	int t = sampleToThresholdMap[f][k];
//	sum[f][t] += labels[k];
//	sqSum[f][t] += labels[k]*labels[k];
//	count doesn't change, so no need to re-compute
// }
/*****************************************************/
(3) 构造回归树来拟合lambda，用均方误差MSE(mean squared error)来作为分裂结点的依据，遍历每一个特征下的样本点，找到MSE最小的最优特征和梯度值来作为回归树的一个分裂点。
RegressionTree rt = new RegressionTree(nTreeLeaves, martSamples, pseudoResponses, hist, minLeafSupport);
rt.fit();

double varLeft = sqSumLeft - sumLeft * sumLeft / countLeft;
double varRight = sqSumRight - sumRight * sumRight / countRight;
double S = varLeft + varRight;

minLeafSupport是算法支持的叶子结点的最小样本个数，请参考B+树的叶子结点。S=varLeft+varRight。S是分裂点的总MSE，对每个Features，遍历它的threshold梯度，求出以每个梯度作分裂点对应的sumLeft(左子树lambda求和), sumRight(右子树lambda求和)， sqSumLeft(左子树lambda平方和)，sqSumRight(右子树lambda平方和)，用这四者求出每个梯度的MSE，一个feature一定有最佳梯度t满足MSE最小，在所有feature的最佳梯度中最小的那个则是整体样本的最佳梯度，记下来这个feature号：bestFeatureIdx、梯度：bestThresholdIdx和左MSE：bestVarLeft、右MSE：bestVarRight和总MSE：minS。
我们有最佳feature和最佳分裂梯度后，就得到了一个树的最佳分裂结点，把最佳feature的样本遍历一遍，看特征值落在分裂点的左边还是右边，若落在左边就把这个样本放进left，若落在右边就放进right。通过逐步迭代出一棵回归树。
/*****************************************************/
3、通过上述步骤我们得到了一棵回归树，但是我们的目标是要训练nTrees=1000棵回归树来组成森林，因此每生成一棵回归树就要加入模型里。
ensemble.add(rt, learningRate);
//它有1000棵回归决策树，每生成一棵都要加入ensembel里直至结束，
//这里的learningRate更像是这棵树的收缩系数(权重)weight
/*****************************************************/
4、更新树的输出(即计算每个叶子节点的数值，参考B+树)
	采用Newton-Raphson求解，对落入该叶子节点的文档集，用公式  计算该叶子节点的输出值。
updateTreeOutput(rt);
//树的输出指的是叶子结点的值avgLabel，假如一个叶子结点有idx.size()个样本：
//for(int j=0;j<idx.length;j++)
//{
//	int k = idx[j];
//	s1 += pseudoResponses[k];//前面代码里样本的lambda值
//	s2 += martSamples[k].getCached();//前面代码里样本的delta值
//}
//s.setOutput(s1/s2);//叶子结点值：avgLabel=s1/s2=lambda/delta值
/*****************************************************/
5、更新训练样本的模型输出值
	这步是给样本(文档)打分，在一棵回归树上：样本得分=样本i在这棵树的值*树的收缩系数(权重)；通过1000棵回归树上样本得分的累加求和即是样本的最终得分，用它来作为排序依据。

for(int i=0;i<modelScores.length;i++)
modelScores[i] += learningRate * rt.eval(martSamples[i]);
//这步是给文档打分，以后就按照这个分数来排序。
//learningRate是这棵树的收缩系数(权重)，rt.eval(dp)是dp所在叶子结点的值avgLabel。
//avgLabel在第6步计算过，avgLabel=s1/s2=lambda/delta，
//理论上文档得分是1000棵回归树叶子结点值avgLabel的求和，
//因此代码和理论完美的契合上了。
/*****************************************************/
6、评价训练模型
	对于训练数据，先把一个query召回的文档排序，然后对排序质量打分，对所有query的排序质量评分并求解出总分。
 	评测代码文件：ciir.umass.edu.metric.METRIC
评测算法：NDCG（Normalized Cumulative Discounted Gain），MRR（Mean Reciprocal Rank），ERR（Expected Reciprocal Rank）等。评测算法是在运行的参数里指定，-metric2t是指定训练文件的评测算法，-metric2T是指定测试文件的评测算法。
scoreOnTrainingData = computeModelScoreOnTraining();
//先把一个query召回的文档RankList排序，排序标准是modelScores[i]
//然后计算该query召回的RankList的得分，对应代码如下：
// float s = 0;
// s += scorer.score(rank(i, current));
/*****************************************************/
7、检验是否应该提前结束
对于验证数据，若一个query召回文档RankList的排序得分是score[i]，对所有query的得分求总和得到排序的整体得分，用它除以数据个数即是最终得分score。构造多棵迭代回归树时，分数最高的score即是最优值，bestScoreOnValidationData是score最高值，bestModelOnValidation是score最高时对应树的下标值，从0开始计数。迭代提前结束的意义是：在最优score出现后，继续迭代100棵树仍然无法超越最优，则停止迭代回归树，100次前的那个score就是最优的，它是在处理局部最优和全局最优时的判断条件，接着来100棵都没找到更好的那就把它算作是全局最优了。
if(m - bestModelOnValidation > nRoundToStopEarly) // nRoundToStopEarly=100
    break;
    ...
/*****************************************************/
8、 回滚到在验证集上最优的模型
	如果迭代提前结束，则要回滚到最优的那棵树为止。
ensemble.remove(ensemble.treeCount()-1);
    ...
}
//把trees和weights的元素删掉，一直删回到最优的那棵树为止，最优树的
//下标是bestModelOnValidation，从0开始编的号码。
//trees.remove(k);
//weights.remove(k);

三、LambdaMart排序质量NDCG评测
1、	NDCG（Normalized discounted cumulative gain）：归一化折损累积增益
思路：对于搜索引擎，如何衡量搜索排序结果？ 我们搜索query召回结果集合RankList：
1、我们希望把最相关的结果放到排名最靠前的位置；
2、我们希望整个列表的结果尽可能的和query相关。
公式：满足上述两点的折损累积增益函数是DCG，其中分子是每个召回文档的增益值，分母是文档的位置损失值。如果增益高的文档被排序在靠后的位置，评测的得分会较低。
 
为了对不同的排序效果进行比较， 我们需要把DCG的值归一化得到NDCG：
 
其中IDCG是理想情况下排序的DCG值，NDCG=实际DCG/理想DCG：
 
NDCG的整体分析公式如下：
    
 

代码中模型得分：首先算出一个query召回文档的排序质量NDCG的分数，累加全部query的NDCG得到总分score，模型得分s = 总分score / query数目。

参考资料：https://en.wikipedia.org/wiki/Discounted_cumulative_gain
/*****************************************************/
Precision
准确率(Precision)=检索到的相关内容 / 所有检索到的内容总数
代码里Precision=label>0的文档数目 / 召回文档总数目
/*****************************************************/

